{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-1 ratio :\n",
    "\n",
    "With Workflow():\n",
    "    model = UnetLoaderGGUF('flux1-fill-dev-Q4_K_S.gguf')\n",
    "    model = DifferentialDiffusion(model)\n",
    "    clip = DualCLIPLoader('clip_l.safetensors', 't5xxl_fp8_e4m3fn.safetensors', 'flux', 'default')\n",
    "    model2, processor = JanusModelLoader('deepseek-ai/Janus-Pro-1B')\n",
    "    image, _ = EasyLoadImageBase64('use the img string here')\n",
    "    text = JanusImageUnderstanding(model2, processor, image, '用英文描述一下这张图片的背景，只描述背景，只描述背景，不要出现任何人物描述', 794902560779472, 0.1, 1, 512)\n",
    "    text = ShowTextPysssss(text)\n",
    "    conditioning = CLIPTextEncode(text, clip)\n",
    "    conditioning = FluxGuidance(conditioning, 30)\n",
    "    conditioning2 = CLIPTextEncode('There are watermark and texts on the images.There are people, there are many people', clip)\n",
    "    conditioning2 = FluxGuidance(conditioning2, 30)\n",
    "    vae = VAELoader('ae.safetensors')\n",
    "    image2 = JWImageResizeByLongerSide(image, 1080, 'bicubic')\n",
    "    width_extension_per_side, height_extension_per_side = CalculateAspectRatioExtension(image2, '1:1', 1, 1)\n",
    "    image3, mask = ExtendCanvasByPercentage(image2, False, True, height_extension_per_side, height_extension_per_side, width_extension_per_side, width_extension_per_side, 0, '#7f7f7f', None)\n",
    "    image3, mask = ExtendCanvasByPercentage(image3, True, False, 5, 0, 8, 8, 8, '#7f7f7f', mask)\n",
    "    positive, negative, latent = InpaintModelConditioning(conditioning, conditioning2, vae, image3, mask, False)\n",
    "    latent = KSampler(model, 785164945698779, 20, 3.5, 'euler', 'normal', positive, negative, latent, 1)\n",
    "    image4 = VAEDecode(latent, vae)\n",
    "    cropped_image, _, _ = ImageCropByPercentage(False, image4, 80, 80, 'top-center', 0, 0)\n",
    "    cropped_image = JWImageResizeByShorterSide(cropped_image, 1080, 'bicubic')\n",
    "    cropped_image, _, _ = ImageCropByPercentage(True, cropped_image, 1080, 1080, 'top-center', 0, 0)\n",
    "    SaveImage(cropped_image, \"ComfyUI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16-9 ratio:\n",
    "\n",
    "With Workflow():\n",
    "    upscale_model = UpscaleModelLoader('RealESRGAN_x4plus.pth')\n",
    "    model = UnetLoaderGGUF('flux1-fill-dev-Q4_K_S.gguf')\n",
    "    model = DifferentialDiffusion(model)\n",
    "    clip = DualCLIPLoader('clip_l.safetensors', 't5xxl_fp8_e4m3fn.safetensors', 'flux', 'default')\n",
    "    model2, processor = JanusModelLoader('deepseek-ai/Janus-Pro-1B')\n",
    "    image, _ = EasyLoadImageBase64('use the img string here')\n",
    "    text = JanusImageUnderstanding(model2, processor, image, '用英文描述一下这张图片的背景，只描述背景，只描述背景，不要出现任何人物描述', 794902560779472, 0.1, 1, 512)\n",
    "    text = ShowTextPysssss(text)\n",
    "    conditioning = CLIPTextEncode(text, clip)\n",
    "    conditioning = FluxGuidance(conditioning, 30)\n",
    "    conditioning2 = CLIPTextEncode('There are watermark and texts on the images.There are people, there are many people', clip)\n",
    "    conditioning2 = FluxGuidance(conditioning2, 30)\n",
    "    vae = VAELoader('ae.safetensors')\n",
    "    image2 = JWImageResizeByLongerSide(image, 1080, 'bicubic')\n",
    "    width_extension_per_side, height_extension_per_side = CalculateAspectRatioExtension(image2, '1:1', 1, 1)\n",
    "    image3, mask = ExtendCanvasByPercentage(image2, False, True, height_extension_per_side, height_extension_per_side, width_extension_per_side, width_extension_per_side, 0, '#7f7f7f', None)\n",
    "    image3, mask = ExtendCanvasByPercentage(image3, True, False, 5, 0, 8, 8, 8, '#7f7f7f', mask)\n",
    "    positive, negative, latent = InpaintModelConditioning(conditioning, conditioning2, vae, image3, mask, False)\n",
    "    latent = KSampler(model, 785164945698779, 20, 3.5, 'euler', 'normal', positive, negative, latent, 1)\n",
    "    image4 = VAEDecode(latent, vae)\n",
    "    _, mask2 = LayerMaskTransparentBackgroundUltra(image4, 'ckpt_base.pth', 'VITMatte', 6, 6, 0.010000000000000002, 0.99, True, 'cuda', 2)\n",
    "    cropped_image, _, _, _ = MaskCropByPercentage(image4, mask2, False, False, 'mask_area', 20, 20, 20, 20, '8', None)\n",
    "    _, mask3 = LayerMaskSegmentAnythingUltraV2(cropped_image, 'sam_vit_l (1.25GB)', 'GroundingDINO_SwinT_OGC (694MB)', 0.30000000000000004, 'VITMatte', 6, 6, 0.15000000000000002, 0.99, True, 'face', 'cuda', 2, False)\n",
    "    cropped_image2, _, _, _ = MaskCropByPercentage(cropped_image, mask3, False, False, 'mask_area', 10, 50, 50, 50, '8', None)\n",
    "    cropped_image2 = UpscaleByFactorWithModelWLSH(upscale_model, cropped_image2, 'nearest-exact', 1.5)\n",
    "    cropped_image2 = JWImageResizeByLongerSide(cropped_image2, 1920, 'bicubic')\n",
    "    cropped_image2, _, _ = ImageCropEssential(cropped_image2, 1920, 1080, 'top-center', 0, 0)\n",
    "    SaveImage(cropped_image2, \"ComfyUI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9-16 ratio:\n",
    "\n",
    "With Workflow():\n",
    "    upscale_model = UpscaleModelLoader('RealESRGAN_x4plus.pth')\n",
    "    model = UnetLoaderGGUF('flux1-fill-dev-Q4_K_S.gguf')\n",
    "    model = DifferentialDiffusion(model)\n",
    "    clip = DualCLIPLoader('clip_l.safetensors', 't5xxl_fp8_e4m3fn.safetensors', 'flux', 'default')\n",
    "    model2, processor = JanusModelLoader('deepseek-ai/Janus-Pro-1B')\n",
    "    image, _ = EasyLoadImageBase64('use the img string here')\n",
    "    text = JanusImageUnderstanding(model2, processor, image, '用英文描述一下这张图片的背景，只描述背景，只描述背景，不要出现任何人物描述', 794902560779472, 0.1, 1, 512)\n",
    "    text = ShowTextPysssss(text)\n",
    "    conditioning = CLIPTextEncode(text, clip)\n",
    "    conditioning = FluxGuidance(conditioning, 30)\n",
    "    conditioning2 = CLIPTextEncode('There are watermark and texts on the images.There are people, there are many people', clip)\n",
    "    conditioning2 = FluxGuidance(conditioning2, 30)\n",
    "    vae = VAELoader('ae.safetensors')\n",
    "    image2 = JWImageResizeByLongerSide(image, 1080, 'bicubic')\n",
    "    width_extension_per_side, height_extension_per_side = CalculateAspectRatioExtension(image2, '1:1', 1, 1)\n",
    "    image3, mask = ExtendCanvasByPercentage(image2, False, True, height_extension_per_side, height_extension_per_side, width_extension_per_side, width_extension_per_side, 0, '#7f7f7f', None)\n",
    "    image3, mask = ExtendCanvasByPercentage(image3, True, False, 5, 0, 8, 8, 8, '#7f7f7f', mask)\n",
    "    positive, negative, latent = InpaintModelConditioning(conditioning, conditioning2, vae, image3, mask, False)\n",
    "    latent = KSampler(model, 785164945698779, 20, 3.5, 'euler', 'normal', positive, negative, latent, 1)\n",
    "    image4 = VAEDecode(latent, vae)\n",
    "    _, mask2 = LayerMaskSegmentAnythingUltraV2(image4, 'sam_vit_l (1.25GB)', 'GroundingDINO_SwinT_OGC (694MB)', 0.30000000000000004, 'VITMatte', 6, 6, 0.15000000000000002, 0.99, True, 'face', 'cuda', 2, False)\n",
    "    cropped_image, _, _, _ = MaskCropByPercentage(image4, mask2, False, False, 'mask_area', 20, 50, 40, 40, '8', None)\n",
    "    cropped_image = UpscaleByFactorWithModelWLSH(upscale_model, cropped_image, 'nearest-exact', 1.8)\n",
    "    cropped_image = JWImageResizeByShorterSide(cropped_image, 1920, 'bicubic')\n",
    "    cropped_image, _, _ = ImageCropEssential(cropped_image, 1080, 1920, 'top-center', 0, 0)\n",
    "    SaveImage(cropped_image, \"ComfyUI\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comfy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
