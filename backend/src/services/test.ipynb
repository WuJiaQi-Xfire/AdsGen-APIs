{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-1 ratio :\n",
    "\n",
    "With Workflow():\n",
    "    model = UnetLoaderGGUF('flux1-fill-dev-Q4_K_S.gguf')\n",
    "    model = DifferentialDiffusion(model)\n",
    "    clip = DualCLIPLoader('clip_l.safetensors', 't5xxl_fp8_e4m3fn.safetensors', 'flux', 'default')\n",
    "    model2, processor = JanusModelLoader('deepseek-ai/Janus-Pro-1B')\n",
    "    image, _ = EasyLoadImageBase64('use the img string here')\n",
    "    text = JanusImageUnderstanding(model2, processor, image, '用英文描述一下这张图片的背景，只描述背景，只描述背景，不要出现任何人物描述', 794902560779472, 0.1, 1, 512)\n",
    "    text = ShowTextPysssss(text)\n",
    "    conditioning = CLIPTextEncode(text, clip)\n",
    "    conditioning = FluxGuidance(conditioning, 30)\n",
    "    conditioning2 = CLIPTextEncode('There are watermark and texts on the images.There are people, there are many people', clip)\n",
    "    conditioning2 = FluxGuidance(conditioning2, 30)\n",
    "    vae = VAELoader('ae.safetensors')\n",
    "    image2 = JWImageResizeByLongerSide(image, 1080, 'bicubic')\n",
    "    width_extension_per_side, height_extension_per_side = CalculateAspectRatioExtension(image2, '1:1', 1, 1)\n",
    "    image3, mask = ExtendCanvasByPercentage(image2, False, True, height_extension_per_side, height_extension_per_side, width_extension_per_side, width_extension_per_side, 0, '#7f7f7f', None)\n",
    "    image3, mask = ExtendCanvasByPercentage(image3, True, False, 5, 0, 8, 8, 8, '#7f7f7f', mask)\n",
    "    positive, negative, latent = InpaintModelConditioning(conditioning, conditioning2, vae, image3, mask, False)\n",
    "    latent = KSampler(model, 785164945698779, 20, 3.5, 'euler', 'normal', positive, negative, latent, 1)\n",
    "    image4 = VAEDecode(latent, vae)\n",
    "    cropped_image, _, _ = ImageCropByPercentage(False, image4, 80, 80, 'top-center', 0, 0)\n",
    "    cropped_image = JWImageResizeByShorterSide(cropped_image, 1080, 'bicubic')\n",
    "    cropped_image, _, _ = ImageCropByPercentage(True, cropped_image, 1080, 1080, 'top-center', 0, 0)\n",
    "    SaveImage(cropped_image, \"ComfyUI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16-9 ratio:\n",
    "\n",
    "With Workflow():\n",
    "    upscale_model = UpscaleModelLoader('RealESRGAN_x4plus.pth')\n",
    "    model = UnetLoaderGGUF('flux1-fill-dev-Q4_K_S.gguf')\n",
    "    model = DifferentialDiffusion(model)\n",
    "    clip = DualCLIPLoader('clip_l.safetensors', 't5xxl_fp8_e4m3fn.safetensors', 'flux', 'default')\n",
    "    model2, processor = JanusModelLoader('deepseek-ai/Janus-Pro-1B')\n",
    "    image, _ = EasyLoadImageBase64('use the img string here')\n",
    "    text = JanusImageUnderstanding(model2, processor, image, '用英文描述一下这张图片的背景，只描述背景，只描述背景，不要出现任何人物描述', 794902560779472, 0.1, 1, 512)\n",
    "    text = ShowTextPysssss(text)\n",
    "    conditioning = CLIPTextEncode(text, clip)\n",
    "    conditioning = FluxGuidance(conditioning, 30)\n",
    "    conditioning2 = CLIPTextEncode('There are watermark and texts on the images.There are people, there are many people', clip)\n",
    "    conditioning2 = FluxGuidance(conditioning2, 30)\n",
    "    vae = VAELoader('ae.safetensors')\n",
    "    image2 = JWImageResizeByLongerSide(image, 1080, 'bicubic')\n",
    "    width_extension_per_side, height_extension_per_side = CalculateAspectRatioExtension(image2, '1:1', 1, 1)\n",
    "    image3, mask = ExtendCanvasByPercentage(image2, False, True, height_extension_per_side, height_extension_per_side, width_extension_per_side, width_extension_per_side, 0, '#7f7f7f', None)\n",
    "    image3, mask = ExtendCanvasByPercentage(image3, True, False, 5, 0, 8, 8, 8, '#7f7f7f', mask)\n",
    "    positive, negative, latent = InpaintModelConditioning(conditioning, conditioning2, vae, image3, mask, False)\n",
    "    latent = KSampler(model, 785164945698779, 20, 3.5, 'euler', 'normal', positive, negative, latent, 1)\n",
    "    image4 = VAEDecode(latent, vae)\n",
    "    _, mask2 = LayerMaskTransparentBackgroundUltra(image4, 'ckpt_base.pth', 'VITMatte', 6, 6, 0.010000000000000002, 0.99, True, 'cuda', 2)\n",
    "    cropped_image, _, _, _ = MaskCropByPercentage(image4, mask2, False, False, 'mask_area', 20, 20, 20, 20, '8', None)\n",
    "    _, mask3 = LayerMaskSegmentAnythingUltraV2(cropped_image, 'sam_vit_l (1.25GB)', 'GroundingDINO_SwinT_OGC (694MB)', 0.30000000000000004, 'VITMatte', 6, 6, 0.15000000000000002, 0.99, True, 'face', 'cuda', 2, False)\n",
    "    cropped_image2, _, _, _ = MaskCropByPercentage(cropped_image, mask3, False, False, 'mask_area', 10, 50, 50, 50, '8', None)\n",
    "    cropped_image2 = UpscaleByFactorWithModelWLSH(upscale_model, cropped_image2, 'nearest-exact', 1.5)\n",
    "    cropped_image2 = JWImageResizeByLongerSide(cropped_image2, 1920, 'bicubic')\n",
    "    cropped_image2, _, _ = ImageCropEssential(cropped_image2, 1920, 1080, 'top-center', 0, 0)\n",
    "    SaveImage(cropped_image2, \"ComfyUI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9-16 ratio:\n",
    "\n",
    "With Workflow():\n",
    "    upscale_model = UpscaleModelLoader('RealESRGAN_x4plus.pth')\n",
    "    model = UnetLoaderGGUF('flux1-fill-dev-Q4_K_S.gguf')\n",
    "    model = DifferentialDiffusion(model)\n",
    "    clip = DualCLIPLoader('clip_l.safetensors', 't5xxl_fp8_e4m3fn.safetensors', 'flux', 'default')\n",
    "    model2, processor = JanusModelLoader('deepseek-ai/Janus-Pro-1B')\n",
    "    image, _ = EasyLoadImageBase64('use the img string here')\n",
    "    text = JanusImageUnderstanding(model2, processor, image, '用英文描述一下这张图片的背景，只描述背景，只描述背景，不要出现任何人物描述', 794902560779472, 0.1, 1, 512)\n",
    "    text = ShowTextPysssss(text)\n",
    "    conditioning = CLIPTextEncode(text, clip)\n",
    "    conditioning = FluxGuidance(conditioning, 30)\n",
    "    conditioning2 = CLIPTextEncode('There are watermark and texts on the images.There are people, there are many people', clip)\n",
    "    conditioning2 = FluxGuidance(conditioning2, 30)\n",
    "    vae = VAELoader('ae.safetensors')\n",
    "    image2 = JWImageResizeByLongerSide(image, 1080, 'bicubic')\n",
    "    width_extension_per_side, height_extension_per_side = CalculateAspectRatioExtension(image2, '1:1', 1, 1)\n",
    "    image3, mask = ExtendCanvasByPercentage(image2, False, True, height_extension_per_side, height_extension_per_side, width_extension_per_side, width_extension_per_side, 0, '#7f7f7f', None)\n",
    "    image3, mask = ExtendCanvasByPercentage(image3, True, False, 5, 0, 8, 8, 8, '#7f7f7f', mask)\n",
    "    positive, negative, latent = InpaintModelConditioning(conditioning, conditioning2, vae, image3, mask, False)\n",
    "    latent = KSampler(model, 785164945698779, 20, 3.5, 'euler', 'normal', positive, negative, latent, 1)\n",
    "    image4 = VAEDecode(latent, vae)\n",
    "    _, mask2 = LayerMaskSegmentAnythingUltraV2(image4, 'sam_vit_l (1.25GB)', 'GroundingDINO_SwinT_OGC (694MB)', 0.30000000000000004, 'VITMatte', 6, 6, 0.15000000000000002, 0.99, True, 'face', 'cuda', 2, False)\n",
    "    cropped_image, _, _, _ = MaskCropByPercentage(image4, mask2, False, False, 'mask_area', 20, 50, 40, 40, '8', None)\n",
    "    cropped_image = UpscaleByFactorWithModelWLSH(upscale_model, cropped_image, 'nearest-exact', 1.8)\n",
    "    cropped_image = JWImageResizeByShorterSide(cropped_image, 1920, 'bicubic')\n",
    "    cropped_image, _, _ = ImageCropEssential(cropped_image, 1080, 1920, 'top-center', 0, 0)\n",
    "    SaveImage(cropped_image, \"ComfyUI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1183450200.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mstack art:\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stack art:\n",
    "\n",
    "def stacked_art(prompt_name, prompt, seed, ratio):\n",
    "    clean_prompt_name = prompt_name.replace(\".txt\", \"\")\n",
    "    with Workflow():\n",
    "        noise = RandomNoise(313190674711926)\n",
    "        model, _, _ = CheckpointLoaderSimple(\"flux1-dev-fp8.safetensors\")\n",
    "        model = ModelSamplingFlux(model, 1.12, 0.5000000000000001, 1024, 1024)\n",
    "        clip = DualCLIPLoader(\n",
    "            \"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\", \"default\"\n",
    "        )\n",
    "        clip_text_encode_positive_prompt_conditioning = CLIPTextEncode(prompt, clip)\n",
    "        clip_text_encode_positive_prompt_conditioning = FluxGuidance(\n",
    "            clip_text_encode_positive_prompt_conditioning, 3.5\n",
    "        )\n",
    "        guider = BasicGuider(model, clip_text_encode_positive_prompt_conditioning)\n",
    "        sampler = KSamplerSelect(\"euler\")\n",
    "        sigmas = BasicScheduler(model, \"simple\", 20, 1)\n",
    "        latent = EmptyLatentImage(1080, 1080, 1)\n",
    "        latent, _ = SamplerCustomAdvanced(noise, guider, sampler, sigmas, latent)\n",
    "        vae = VAELoader(\"ae.safetensors\")\n",
    "        image = VAEDecode(latent, vae)\n",
    "        filename = f\"{clean_prompt_name}_stacked_art_{seed}\"\n",
    "        _, _ = GregSaveImageWithSuffix(\n",
    "            image,\n",
    "            True,\n",
    "            file_path,\n",
    "            filename,\n",
    "            \"_\",\n",
    "            \"\",\n",
    "            4,\n",
    "            \"false\",\n",
    "            \"true\",\n",
    "            \"png\",\n",
    "            300,\n",
    "            100,\n",
    "            \"true\",\n",
    "            \"false\",\n",
    "            \"false\",\n",
    "            \"false\",\n",
    "            \"false\",\n",
    "            \"true\",\n",
    "            \"false\",\n",
    "        )\n",
    "        if ratio == \"1:1\":\n",
    "            new_filename = f\"{filename}_1_1\"\n",
    "            _, _ = GregSaveImageWithSuffix(\n",
    "                image,\n",
    "                True,\n",
    "                preview_path,\n",
    "                new_filename,\n",
    "                \"_\",\n",
    "                \"\",\n",
    "                4,\n",
    "                \"false\",\n",
    "                \"true\",\n",
    "                \"png\",\n",
    "                300,\n",
    "                100,\n",
    "                \"true\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"true\",\n",
    "                \"false\",\n",
    "            )\n",
    "            return\n",
    "        model2 = UnetLoaderGGUF(\"flux1-fill-dev-Q4_K_S.gguf\")\n",
    "        model2 = DifferentialDiffusion(model2)\n",
    "        model3, processor = JanusModelLoader(\"deepseek-ai/Janus-Pro-1B\")\n",
    "        text = JanusImageUnderstanding(\n",
    "            model3,\n",
    "            processor,\n",
    "            image,\n",
    "            \"用英文描述一下这张图片的背景，只描述背景，只描述背景，不要出现任何人物描述\",\n",
    "            794902560779472,\n",
    "            0.1,\n",
    "            1,\n",
    "            512,\n",
    "        )\n",
    "        conditioning = CLIPTextEncode(text, clip)\n",
    "        conditioning = FluxGuidance(conditioning, 30)\n",
    "        conditioning2 = CLIPTextEncode(\n",
    "            \"There are watermark and texts on the images.There are people, there are many people\",\n",
    "            clip,\n",
    "        )\n",
    "        conditioning2 = FluxGuidance(conditioning2, 30)\n",
    "        image2 = JWImageResizeByLongerSide(image, 1080, \"bicubic\")\n",
    "        width_extension_per_side, height_extension_per_side = (\n",
    "            CalculateAspectRatioExtension(image2, \"1:1\", 1, 1)\n",
    "        )\n",
    "        image3, mask = ExtendCanvasByPercentage(\n",
    "            image2,\n",
    "            False,\n",
    "            True,\n",
    "            height_extension_per_side,\n",
    "            height_extension_per_side,\n",
    "            width_extension_per_side,\n",
    "            width_extension_per_side,\n",
    "            0,\n",
    "            \"#7f7f7f\",\n",
    "            None,\n",
    "        )\n",
    "        image3, mask = ExtendCanvasByPercentage(\n",
    "            image3, True, False, 5, 0, 8, 8, 8, \"#7f7f7f\", mask\n",
    "        )\n",
    "        positive, negative, latent = InpaintModelConditioning(\n",
    "            conditioning, conditioning2, vae, image3, mask, False\n",
    "        )\n",
    "        latent = KSampler(\n",
    "            model2,\n",
    "            785164945698779,\n",
    "            20,\n",
    "            3.5,\n",
    "            \"euler\",\n",
    "            \"normal\",\n",
    "            positive,\n",
    "            negative,\n",
    "            latent,\n",
    "            1,\n",
    "        )\n",
    "        image4 = VAEDecode(latent, vae)\n",
    "        upscale_model = UpscaleModelLoader(\"RealESRGAN_x4plus.pth\")\n",
    "        if ratio == \"16:9\":\n",
    "            _, mask2 = LayerMaskTransparentBackgroundUltra(\n",
    "                image4,\n",
    "                \"ckpt_base.pth\",\n",
    "                \"VITMatte\",\n",
    "                6,\n",
    "                6,\n",
    "                0.010000000000000002,\n",
    "                0.99,\n",
    "                True,\n",
    "                \"cuda\",\n",
    "                2,\n",
    "            )\n",
    "            cropped_image, _, _, _ = MaskCropByPercentage(\n",
    "                image4, mask2, False, False, \"mask_area\", 20, 20, 20, 20, \"8\", None\n",
    "            )\n",
    "            _, mask3 = LayerMaskSegmentAnythingUltraV2(\n",
    "                cropped_image,\n",
    "                \"sam_vit_l (1.25GB)\",\n",
    "                \"GroundingDINO_SwinT_OGC (694MB)\",\n",
    "                0.30000000000000004,\n",
    "                \"VITMatte\",\n",
    "                6,\n",
    "                6,\n",
    "                0.15000000000000002,\n",
    "                0.99,\n",
    "                True,\n",
    "                \"face\",\n",
    "                \"cuda\",\n",
    "                2,\n",
    "                False,\n",
    "            )\n",
    "            cropped_image2, _, _, _ = MaskCropByPercentage(\n",
    "                cropped_image,\n",
    "                mask3,\n",
    "                False,\n",
    "                False,\n",
    "                \"mask_area\",\n",
    "                10,\n",
    "                50,\n",
    "                50,\n",
    "                50,\n",
    "                \"8\",\n",
    "                None,\n",
    "            )\n",
    "            cropped_image2 = UpscaleByFactorWithModelWLSH(\n",
    "                upscale_model, cropped_image2, \"nearest-exact\", 1.5\n",
    "            )\n",
    "            cropped_image2 = JWImageResizeByLongerSide(cropped_image2, 1920, \"bicubic\")\n",
    "            cropped_image2, _, _ = ImageCropEssential(\n",
    "                cropped_image2, 1920, 1080, \"top-center\", 0, 0\n",
    "            )\n",
    "            new_filename = f\"{filename}_16_9\"\n",
    "            _, _ = GregSaveImageWithSuffix(\n",
    "                cropped_image2,\n",
    "                True,\n",
    "                preview_path,\n",
    "                new_filename,\n",
    "                \"_\",\n",
    "                \"\",\n",
    "                4,\n",
    "                \"false\",\n",
    "                \"true\",\n",
    "                \"png\",\n",
    "                300,\n",
    "                100,\n",
    "                \"true\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"true\",\n",
    "                \"false\",\n",
    "            )\n",
    "        elif ratio == \"9:16\":\n",
    "            _, mask2 = LayerMaskSegmentAnythingUltraV2(\n",
    "                image4,\n",
    "                \"sam_vit_l (1.25GB)\",\n",
    "                \"GroundingDINO_SwinT_OGC (694MB)\",\n",
    "                0.30000000000000004,\n",
    "                \"VITMatte\",\n",
    "                6,\n",
    "                6,\n",
    "                0.15000000000000002,\n",
    "                0.99,\n",
    "                True,\n",
    "                \"face\",\n",
    "                \"cuda\",\n",
    "                2,\n",
    "                False,\n",
    "            )\n",
    "            cropped_image, _, _, _ = MaskCropByPercentage(\n",
    "                image4, mask2, False, False, \"mask_area\", 20, 50, 40, 40, \"8\", None\n",
    "            )\n",
    "            cropped_image = UpscaleByFactorWithModelWLSH(\n",
    "                upscale_model, cropped_image, \"nearest-exact\", 1.8\n",
    "            )\n",
    "            cropped_image = JWImageResizeByShorterSide(cropped_image, 1920, \"bicubic\")\n",
    "            cropped_image, _, _ = ImageCropEssential(\n",
    "                cropped_image, 1080, 1920, \"top-center\", 0, 0\n",
    "            )\n",
    "            new_filename = f\"{filename}_9_16\"\n",
    "            _, _ = GregSaveImageWithSuffix(\n",
    "                cropped_image,\n",
    "                True,\n",
    "                preview_path,\n",
    "                new_filename,\n",
    "                \"_\",\n",
    "                \"\",\n",
    "                4,\n",
    "                \"false\",\n",
    "                \"true\",\n",
    "                \"png\",\n",
    "                300,\n",
    "                100,\n",
    "                \"true\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"false\",\n",
    "                \"true\",\n",
    "                \"false\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comfy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
